{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Analysis Codebase:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "    \n",
    "The following sections present our current codebase that analyzes various combinations of attributes present in the raw JSON Twitter data file and CSV Twitter data file.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Creation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "We create out dataset using the function call below and \"dataset_processor_adapted.py\".\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Absolute file path.\n",
    "    create_dataset(\"D:/Dropbox/summer-research-2019/json/dataset_slo_20100101-20180510.json\",\n",
    "                   \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/selected-attributes-final3.csv\",\n",
    "                   \"utf-8\", False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Analysis Utility Functions:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "The following sample function calls illustrate how we use the utility functions in \"slo_twitter_data_analysis_utility_functions.py\" to perform individual attribute extraction/export and data chuncking extraction/export.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Extract multiple fields from raw JSON file and export to CSV file.\n",
    "    tweet_util.generalized_multi_field_extraction_function(\n",
    "        \"D:/Dropbox/summer-research-2019/json/dataset_slo_20100101-20180510.json\",\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\",\n",
    "        [\"retweet_count\", \"retweeted\", \"favorite_count\", \"favorited\"], \"csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Extract various individual fields from raw JSON file and export to CSV/JSON file.\n",
    "    tweet_util.generalized_field_extraction_function(\n",
    "        \"D:/Dropbox/summer-research-2019/json/dataset_slo_20100101-20180510.json\",\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/\",\n",
    "        \"id\", \"csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Read in JSON/CSV data as chunks and export to CSV/JSON files.\n",
    "    tweet_util.generalized_data_chunking_file_export_function(\n",
    "        \"D:/Dropbox/summer-research-2019/json/dataset_slo_20100101-20180510.json\",\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/dataset-chunks/\", \"csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Refer to the Python file itself if interested in that codebase.  Several graphing helper functions are also included.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries and set parameters:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "We import the required libraries as well as our custom utility functions for data anlysis.\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import custom utility functions.\n",
    "import slo_twitter_data_analysis_utility_functions as tweet_util"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Pandas settings alters the maximum number of rows to be displayed and the number of decimal places to display for floating point values.  We also filter out several warning types to reduce potential output clutter.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adjust parameters to display all contents.\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "pd.options.display.max_colwidth = 1000\n",
    "# Seaborn setting.\n",
    "sns.set()\n",
    "# Set level of precision for float value output.\n",
    "pd.set_option('precision', 12)\n",
    "# Ignore these types of warnings - don't output to console.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Change log levels between \"INFO\" and \"DEBUG\" depending on whether you wish to see log output or not.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.INFO)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Display raw JSON file data chunk dataframe information:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "By specifying \"none\" as the function name, we simply print out logger INFO on the shape, columns, and a single sample of the dataframe on the first chunk of data.<br>\n",
    "\n",
    "Note: We use this function instead of the one in the previous code cell as the raw JSON file is too large to fit into system RAM.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Specify and call data analysis functions on chunked raw JSON Tweet file.\n",
    "    tweet_util.call_data_analysis_function_on_json_file_chunks(\n",
    "        \"D:/Dropbox/summer-research-2019/json/dataset_slo_20100101-20180510.json\", \"none\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "As can be seen, each Tweet object in its raw JSON form contains many different attributes.  The \"user\" attribute is a Object itself that especially contains many other attributes and Objects.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import raw JSON converted to CSV  Twitter dataset file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "We read in the untokenized Twitter dataset as a CSV file and generate a Pandas dataframe from the dataset.<br>\n",
    "\n",
    "Note: Does not contain all fields from the raw JSON file; only the ones we are currently interested in analyzing.  We will append columns to the CSV file as necessary if additional attributes become relevant for analysis.  Anything with \"custom\" is a derived column created via .apply(function) to the native attributes.<br>\n",
    "\n",
    "Note: flattened, so no nested structures.\n",
    "\n",
    "Note 2: re-create a fresh dataset without shuffling data to preserve same order in JSON file.\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    # Import dataset and convert to dataframe.\n",
    "    tweet_csv_dataframe = tweet_util.import_dataset(\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/selected-attributes-final.csv\",\n",
    "        \"csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    " \n",
    "The above log.INFO output shows the shape, columns, and a sample from the Pandas Dataframe that contains the entirety of the CSV file.<br>\n",
    " \n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resources Used:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "**TODO: convert to annotated bibliography**\n",
    "\n",
    "Dataset Files (obtained from Borg supercomputer):<br>\n",
    "\n",
    "dataset_slo_20100101-20180510.json<br>\n",
    "dataset_20100101-20180510.csv<br>\n",
    "\n",
    "Note: These are large fiels not included in the project GitHub Repository.<br>\n",
    "\n",
    "\n",
    "- [SLO-analysis.ipynb](SLO-analysis.ipynb)<br>\n",
    "    -original SLO Twitter data analysis file from Shuntaro Yada.<br>\n",
    "\n",
    "\n",
    "- https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json<br>\n",
    "    -explanation of all data fields in JSON file format for Tweets.<br>\n",
    "\n",
    "\n",
    "- https://datatofish.com/export-dataframe-to-csv/<br>\n",
    "- https://datatofish.com/export-pandas-dataframe-json/<br>\n",
    "    -saving Pandas dataframe to CSV/JSON<br>\n",
    "    \n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html<br>\n",
    "    -Pandas to_datetime() function call.<br>\n",
    "    \n",
    "\n",
    "- https://www.machinelearningplus.com/plots/matplotlib-tutorial-complete-guide-python-plot-examples/<br>\n",
    "    -plotting with matplotlib.<br>\n",
    "\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO's:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Implement further elements from Shuntaro Yada's SLO Twitter Dataset Analysis.<br>\n",
    "\n",
    "</span>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}