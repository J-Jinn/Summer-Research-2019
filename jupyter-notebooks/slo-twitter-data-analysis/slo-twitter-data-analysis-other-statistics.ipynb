{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLO Twitter Data Analysis  - Pandas.describe() and Nan/Non-NaN Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary attribute/field names for data analysis functions below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "These Lists containing the attribute/column names in our CSV dataset are necessary for the two data analysis functions below.  These were copy/pasted from our \"dataset_processor.adapted.py\" Python file which contains the codebase to construct the CSV dataset from the raw JSON dataset.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    original_fields = ['created_at', 'id', 'full_text', 'in_reply_to_status_id',\n",
    "                       'in_reply_to_user_id', 'in_reply_to_screen_name',\n",
    "                       'retweet_count', 'favorite_count', 'lang']\n",
    "\n",
    "    tweet_fields = ['tweet_created_at', 'tweet_id', 'tweet_full_text', 'tweet_in_reply_to_status_id',\n",
    "                    'tweet_in_reply_to_user_id', 'tweet_in_reply_to_screen_name',\n",
    "                    'tweet_retweet_count', 'tweet_favorite_count', 'tweet_lang']\n",
    "\n",
    "    user_fields = ['user_id', 'user_name', 'user_screen_name', 'user_location', 'user_description',\n",
    "                   'user_followers_count', 'user_friends_count', 'user_listed_count', 'user_favourites_count',\n",
    "                   'user_statuses_count', 'user_created_at', 'user_time_zone', 'user_lang']\n",
    "\n",
    "    entities_fields = [\"tweet_entities_expanded_urls\", \"tweet_entities_hashtags\", \"tweet_entities_user_mentions_id\",\n",
    "                       \"tweet_entities_user_mentions_name\", \"tweet_entities_user_mentions_screen_name\",\n",
    "                       \"tweet_entities_symbols\"]\n",
    "\n",
    "    additional_fields = [\"company_derived_designation\", \"user_description_text_length\"]\n",
    "\n",
    "    required_fields = ['retweeted_derived', 'company_derived', 'text_derived',  # \"tweet_quoted_status_id\",\n",
    "                       'tweet_url_link_derived', 'multiple_companies_derived', 'multiple_companies_derived_count',\n",
    "                       'tweet_text_length_derived'] + tweet_fields + user_fields + entities_fields + additional_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas.describe() Analysis for Twitter dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Here, we output statistics for each attribute/column in the entire CSV dataset.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def attribute_describe(input_file_path, attribute_name_list, file_type):\n",
    "    \"\"\"\n",
    "    Function utilizes Pandas \"describe\" function to return dataframe statistics.\n",
    "\n",
    "    https://chrisalbon.com/python/data_wrangling/pandas_dataframe_descriptive_stats/\n",
    "\n",
    "    Note: This function will not work for attributes whose values are \"objects\" themselves.\n",
    "    (can only be numeric type or string)\n",
    "\n",
    "    :param input_file_path: absolute file path of the dataset in CSV format.\n",
    "    :param attribute_name_list:  list of names of the attributes we are analyzing.\n",
    "    :param file_type: type of input file.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if file_type == \"csv\":\n",
    "        twitter_data = pd.read_csv(f\"{input_file_path}\", sep=\",\")\n",
    "    elif file_type == \"json\":\n",
    "        twitter_data = pd.read_json(f\"{input_file_path}\",\n",
    "                                    orient='records',\n",
    "                                    lines=True)\n",
    "    else:\n",
    "        print(f\"Invalid file type entered - aborting operation\")\n",
    "        return\n",
    "\n",
    "    # Create a empty Pandas dataframe.\n",
    "    dataframe = pd.DataFrame(twitter_data)\n",
    "\n",
    "    for attribute_name in attribute_name_list:\n",
    "        print(f\"\\nPandas describe for \\\"{attribute_name}\\\":\\n\")\n",
    "        print(dataframe[attribute_name].describe(include='all'))\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time) / 60.0\n",
    "    log.debug(f\"The time taken to visualize the statistics is {time_elapsed} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "The usual data analysis function call.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # Analyze full-text.\n",
    "    attribute_describe(\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/selected-attributes-final.csv\",\n",
    "        required_fields, \"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "The statistics displayed depend on the type of data present as values for each attribute.  For numerical data, we get count, mean, std, min, percentiles, and max.  For categorical data, we get count, unique, top, and frequency.<Br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN versus non-Nan Counts for each Attribute in the Twitter dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "This function displays statistics that count the # of rows/examples in the dataset that are NaN or non-Nan using the Pandas \".isnull().sum()\" function chain.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_nan_non_nan(input_file_path, attribute_name_list, file_type):\n",
    "    \"\"\"\n",
    "    Function counts the number of NaN and non-Nan examples in a Pandas dataframe for the specified columns.\n",
    "\n",
    "    :param input_file_path: absolute file path of the dataset in CSV format.\n",
    "    :param attribute_name_list:  list of names of the attributes we are analyzing.\n",
    "    :param file_type: type of input file.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if file_type == \"csv\":\n",
    "        twitter_data = pd.read_csv(f\"{input_file_path}\", sep=\",\", dtype=object)\n",
    "    elif file_type == \"json\":\n",
    "        twitter_data = pd.read_json(f\"{input_file_path}\",\n",
    "                                    orient='records',\n",
    "                                    lines=True)\n",
    "    else:\n",
    "        print(f\"Invalid file type entered - aborting operation\")\n",
    "        return\n",
    "\n",
    "    # Create a empty Pandas dataframe.\n",
    "    dataframe = pd.DataFrame(twitter_data)\n",
    "\n",
    "    number_examples = dataframe.shape[0]\n",
    "    number_attributes = dataframe.shape[1]\n",
    "    print(f\"\\nThe number of rows (examples) in the dataframe is {number_examples}\")\n",
    "    print(f\"The number of columns (attributes) in the dataframe is {number_attributes}\\n\")\n",
    "\n",
    "    for attribute_name in attribute_name_list:\n",
    "        null_examples = dataframe[attribute_name].isnull().sum()\n",
    "        non_null_examples = number_examples - null_examples\n",
    "\n",
    "        print(f\"The number of NaN rows for \\\"{attribute_name}\\\" is {null_examples}\")\n",
    "        print(f\"The number of non-NaN rows for \\\"{attribute_name}\\\" is {non_null_examples}\\n\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time) / 60.0\n",
    "    log.debug(f\"The time taken to visualize the statistics is {time_elapsed} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "The usual data analysis function call.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # Determine the number of NaN and non-NaN rows for a attribute in a dataset.\n",
    "    count_nan_non_nan(\n",
    "        \"D:/Dropbox/summer-research-2019/jupyter-notebooks/attribute-datasets/selected-attributes-final.csv\",\n",
    "        required_fields, \"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "The attribute name is in double quotations.  Each pair of lines in between a blank line is the statistics for a single attribute.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "**TODO: convert to annotated bibliography**\n",
    "\n",
    "Dataset Files (obtained from Borg supercomputer):<br>\n",
    "\n",
    "dataset_slo_20100101-20180510.json<br>\n",
    "dataset_20100101-20180510.csv<br>\n",
    "\n",
    "Note: These are large fiels not included in the project GitHub Repository.<br>\n",
    "\n",
    "\n",
    "- [SLO-analysis.ipynb](SLO-analysis.ipynb)<br>\n",
    "    -original SLO Twitter data analysis file from Shuntaro Yada.<br>\n",
    "\n",
    "\n",
    "- https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json<br>\n",
    "    -explanation of all data fields in JSON file format for Tweets.<br>\n",
    "\n",
    "\n",
    "- https://datatofish.com/export-dataframe-to-csv/<br>\n",
    "- https://datatofish.com/export-pandas-dataframe-json/<br>\n",
    "    -saving Pandas dataframe to CSV/JSON<br>\n",
    "    \n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html<br>\n",
    "    -Pandas to_datetime() function call.<br>\n",
    "    \n",
    "\n",
    "- https://www.machinelearningplus.com/plots/matplotlib-tutorial-complete-guide-python-plot-examples/<br>\n",
    "    -plotting with matplotlib.<br>\n",
    "\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO's:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Papyrus; font-size:1.25em;\">\n",
    "\n",
    "Implement further elements from Shuntaro Yada's SLO Twitter Dataset Analysis.<br>\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
